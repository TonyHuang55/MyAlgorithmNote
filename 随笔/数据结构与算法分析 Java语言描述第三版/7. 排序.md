# 7 排序

## 7.1 插入排序
### 7.1.1 算法
最简单的排序算法之一是 **插入排序 (insertion sort)** 。插入排序由 N - 1 趟排序组成。对于 p = 1 到 N - 1 趟，插入排序保证从位置 0 到 位置 p 上的元素为已排序状态。插入排序利用了这样的事实：已知位置 0 到位置 p - 1 上的元素已经处于排过序的状态。

在第 p 趟，我们将位置 p 上的元素向左移动，直到它在前 p + 1 个元素中的正确位置被找到的地方。

```java
public static <E extends Comparable<? super E>> void insertionSort(E[] a) {
    int j;

    for (int p = 1; p < a.length; p++) {
        // 位置 p 上的元素存储于 tmp
        E tmp = a[p];
        // p 之前所有更大的元素都被向右移动一个位置
        for (j = p; j > 0 && tmp.compareTo(a[j - 1]) < 0; j--) {
            a[j] = a[j - 1];
        }
        // tmp 被置于正确的位置上
        a[j] = tmp;
    }
}
```

### 7.1.2 插入排序的分析
由于嵌套循环的每一个都花费 N 次迭代，因此插入排序为 O(N<sup>2</sup>)，而且这个界是精确的，因为以反序的输入可以达到该界。循环中元素的比较次数对于 p 的每个值最多是 p + 1 次。

如果输入的数据已预先排序，那么运行时间为 O(N)，因为内层 for 循环的检测总是立即判定不成立而终止。事实上，如果输入几乎被排序，那么插入排序将运行得很快。由于这种变化差别很大，因此值得我们去分析该算法平均情形的行为。实际上，和各种其他排序算法一样，插入排序的平均情形也是 O(N)。

## 7.2 一些简单排序算法的下界
成员是数的数组的逆序 (inversion) 即具有性质 i < j 但 a[i] > a[j] 的序偶(a[i]，a[j])。这正好是需要由插入排序 (隐含) 执行的交换次数。交换两个不按顺序排列的相邻元素恰好消除一个逆序，而一个排过序的数组没有逆序。由于算法中还有 O(N) 量的其他工作，因此插入排序的运行时间是 O(I + N) ，其中 I 为原始数组中的逆序数。于是，若逆序数是 O(N) ，插入排序以线性时间运行。

可以通过计算排列中的平均逆序数得出插入排序平均运行时间的精确的界。如往常一样，定义平均是一个困难的课题。假设不存在重复元素，输入数据是前 N 个整数的某个排列并设所有的排列都是等可能的。在上述假设下，可以得到以下定理：

* N 个互异数的数组的平均逆序数是 N * (N - 1) / 4
    * 意味着插入排序平均是二次的，同时也提供了只交换相邻元素的任何算法的一个很强的下界
* 通过交换相邻元素进行排序的任何算法平均都需要 O (N<sup>2</sup>) 时间。

下界告诉我们，为了使一个排序算法以亚二次或 O (N<sup>2</sup>) 时间运行，必须执行一些比较，特别是要对相距较远的元素进行交换。一个排序算法通过删除逆序得以向前进行，而为了有效地进行，它必须使每次交换删除不止一个逆序。

## 7.3 希尔排序
### 7.3.1 希尔排序的概念和实现
希尔排序 (Shellsort) 的名称源于它的发明者 Donald Shell，该算法是冲破二次时间屏障的第一批算法之一，不过直到它最初发现的若干年后才证明了它的亚二次时间界。它通过比较相距一定间隔的元素来工作；各趟比较所用的距离随着算法的进行而减少，直到只比较相邻元素的最后一趟排序位置。由于这个原因，希尔排序也被叫做 **缩减增量排序 (diminishing increment sort)** 。

希尔排序使用一个序列 h<sub>1</sub> ~ h<sub>t</sub>，叫做 **增量序列 (increment sequence)**。只要 h<sub>1</sub> = 1，任何增量序列都是可行的，不过有些增量序列比另一些效果更好。在使用增量 h<sub>k</sub> 的一趟排序之后，对于每一个 i 我们都有 a[i] ≤ a[i + h<sub>k</sub>]；所有相隔 h<sub>k</sub> 的元素都被排序。此时称文件是 h<sub>k</sub> 排序的 (h<sub>k</sub> - sorted)。希尔排序的一个重要性质是，一个 h<sub>k</sub> 排序的文件保持它的 h<sub>k</sub> 排序性。

h<sub>k</sub> 排序的一般做法是，对于 h<sub>k</sub> ~ N - 1 中每一个位置 i，把其上的元素放到 i，i - h<sub>k</sub>，i - 2h<sub>k</sub> ... 中的正确位置上。一趟 h<sub>k</sub> 排序的作用就是对 h<sub>k</sub> 个独立的子数组执行一次插入排序。

增量序列的一个流行的选择是使用 Shell 建议的序列：h<sub>t</sub> = [N / 2] 和 h<sub>k</sub> = [h<sub>k + 1</sub> / 2]。

```java
public static <E extends Comparable<? super E>> void shellsort(E[] a) {
    int j;

    for (int gap = a.length / 2; gap > 0; gap /= 2) {
        for (int i = gap; i < a.length; i++) {
            E tmp = a[i];
            for (j = i; j >= gap && tmp.compareTo(a[j - gap]) < 0; j -= gap) {
                a[j] = a[j - gap];
            }
            a[j] = tmp;
        }
    }
}
```

### 7.3.2 希尔排序的最坏情形分析
希尔排序编程简单，但是运行时间依赖于增量序列的选择。
* 使用希尔增量时希尔排序的最坏情形运行时间为 O(N<sup>2</sup>)
    * 选择 N 是 2 的幂，使得除了最后一个增量是 1 外所有的增量都是偶数。偶数位置上有 N/2 个同为最大是数，奇数位置上有 N/2 个同为最小的数。由于除了最后一个增量外所有的增量都是侯树，因此在进行最后一趟排序前，N/2 个最大的元素仍然在偶数位置上，N/2 个最小的元素也还是在奇数位置上。于是在最后一趟排序前，后一趟排序开始之前第 i 个最小的数在位置 2i - 1 上。将第 i 个元素恢复到其正确位置需要在数组中移动 i - 1 个间隔。这样仅仅将 N/2 个最小的元素放到正确的位置上就需要至少 O(N<sup>2</sup>) 的工作。
    * 希尔增量的问题在于，这些增量对未必是互素的，因此较小的增量可能影响很小。
* 使用 Hibbard 增量的希尔排序的最坏情形运行时间为 O(N<sup>3/2</sup>)
    * Hibbard 的增量形如 1、3、7 ... 2<sup>k</sup> - 1 。虽然正能量几乎相同，但关键的区别是相邻的增量没有公因子。

## 7.4 堆排序
### 7.4.1 堆排序的概念和实现
先前学习的优先队列可以用于以 O(N log N) 时间的排序。基于该思想的算法叫做堆排序 (heapsort) ，它给出了我们至今所见到的最佳的大 O 的运行时间。

回忆建立 N 个元素的二叉堆的基本策略，这个阶段花费 O(N) 时间。然后我们执行 N 次 deletemin 操作。按照顺序，最小的元素先离开堆。通过将这些元素记录到第二个数组然后再将数组拷贝回来，得到 N 个元素的排序。由于每个 deleteMin 花费时间 O(log N) ，因此总的运行时间是 O(N log N)。

该算法的主要问题在于它使用了一个附加数组。因此，存储需求增加一倍。在某些实例中可能是个问题。注意，将第二个数组拷贝回第一个数组的附加时间消耗只是 O(N)，这不可能显著影响运行时间。这里的问题是空间的问题。

回避使用第二个数组的聪明的方法是利用这样的事实：在每次 deleteMin 之后，堆缩小 1 。因此，位于堆中最后的单元可以用来存放刚刚删去的元素。使用这种策略，在最后一次 deleteMin 后，该数组将以递减的顺序包含这些元素。如果我们想要这些元素排成更典型的递增顺序，那么可以改变有序的特性使得父亲的关键字的值大于儿子的关键字的值。这样就得到 (max) 堆。

在我们的实现方法中将使用一个 (max) 堆，但由于速度的原因避免了实际的 ADT。照通常的习惯，每件事都是在数组中完成的。第一步以线性时间建立一个堆；然后通过每次将堆中的最后元素与第一个元素交换，执行 N - 1 次 deleteMin 操作，每次将堆的大小缩减 1 并进行下滤；当算法终止时，数组则以排好的顺序包含这些元素。

```java
private static int leftChild(int i) {
        return 2 * i + 1;
    }

private static <E extends Comparable<? super E>> void percDown(E[] a, int i, int n) {
    int child;
    E tmp;

    for (tmp = a[i]; leftChild(i) < n; i = child) {
        child = leftChild(i);
        if (child != n - 1 && a[child].compareTo(a[child + 1]) < 0)
            child++;
        if (tmp.compareTo(a[child]) < 0)
            a[i] = a[child];
        else
            break;
    }
    a[i] = tmp;
}

public static <E extends Comparable<? super E>> void swapReferences(E[] a, int left, int right) {
    E temp;
    temp = a[left];
    a[left] = a[right];
    a[right] = temp;
}

public static <E extends Comparable<? super E>> void heapsort(E[] a) {
    for (int i = a.length / 2 - 1; i >= 0; i--)
        percDown(a, i, a.length);
    for (int i = a.length - 1; i > 0; i--) {
        swapReferences(a, 0, i);
        percDown(a, 0, i);
    }
}
```

### 7.4.2 堆排序的分析
第一阶段构建堆最多用到 2N 次比较；在第二阶段，第 i 次 deleteMin 最多用到 2 [log i] 次比较，总数最多 2N logN - O(N) 次比较 (设 N ≥ 2)。因此，在最坏的情形下堆排序最多使用 2N logN - O(N) 次比较。

经验表明，堆排序是一个非常稳定的算法：它使用的比较平均只比最坏情形指出的略少。多年来，还没有人能够指出堆排序平均运行时间的非平凡界。似乎问题在于连续的 deleteMin 操作破坏了堆的随机性，使得概率论证非常复杂。

## 7.5 归并排序
### 7.5.1 归并排序的概念和实现
归并排序 (mergesort) 以 O(N log N) 最坏情形时间运行，而且所使用的比较次数几乎是最优的。它是递归算法一个好的实例。

这个算法中基本的操作是合并两个已排序的表。因为这两个表是已排序的，所以若将输出放到第三个表中，则该算法可以通过对输入数据一趟排序来完成。基本的合并算法是取两个输入数组 A 和 B，一个输出数组 C，以及三个计数器 Actr、Bctr、Cctr，它们初始置于对应数组的开始端。A[Actr] 和 B[Bctr] 中的较小者被拷贝到 C 中的下一个位置，相关的计数器向前推进一步。当两个输入表有一个用完的时候，将另一个表中剩余部分拷贝到 C 中。

合并两个已排序的表的时间显然是线性的，因为最多进行 N - 1 次比较，其中 N 是元素的总数。为了看清这一点，注意每次比较都把一个元素添加到 C 中，但最后的比较除外，它至少添加两个元素。

因此，归并排序算法很容易描述。如果 N = 1 ，那么只有一个元素需要排序，答案是显然的。否则递归地将前半部分数据和后半部分数据各自归并排序，得到排序后的两部分数据，然后使用上面描述的合并算法再将这两部分合并到一起。该算法是经典的分治 (divide - and - conquer) 策略，它将问题分 (divide) 成一些小的问题然后递归求解，而治 (conquer) 的阶段则将分的阶段解得的各答案修补在一起。分而治之是递归非常有效的用法。

```java
private static <E extends Comparable<? super E>> void mergeSort(E[] a, E[] tmpArray, int left, int right) {
    if (left < right) {
        int center = (left + right) / 2;
        mergeSort(a, tmpArray, left, center);
        mergeSort(a, tmpArray, center + 1, right);
        merge(a, tmpArray, left, center + 1, right);
    }
}

public static <E extends Comparable<? super E>> void mergeSort(E[] a) {
    E[] tmpArray = (E[]) new Comparable[a.length];
    mergeSort(a, tmpArray, 0, a.length - 1);
}

/**
 * 如果对 merge 的每个递归调用均局部声明一个临时数组，那么在任一时刻就可能有 log N 个临时数组处在活动期
 * 由于 merge 是 mergeSort 的最后一行，因此在任一时刻只需要一个临时数组在活动，我们还可以使用该临时数组的任意部分
 */
private static <E extends Comparable<? super E>> void merge(E[] a, E[] tmpArray, int leftPos, int rightPos, int rightEnd) {
    int leftEnd = rightPos - 1;
    int tmpPos = leftPos;
    int numElements = rightEnd - leftPos + 1;

    while (leftPos <= leftEnd && rightPos <= rightEnd)
        if (a[leftPos].compareTo(a[rightPos]) <= 0)
            tmpArray[tmpPos++] = a[leftPos++];
        else
            tmpArray[tmpPos++] = a[rightPos++];

    while (leftPos <= leftEnd)
        tmpArray[tmpPos++] = a[leftPos++];

    while (rightPos <= rightEnd)
        tmpArray[tmpPos++] = a[rightPos++];

    for (int i = 0; i < numElements; i++, rightEnd--) {
        a[rightEnd] = tmpArray[rightEnd];
    }
}
```

### 7.5.2 归并排序的分析
归并排序是用于分析递归例程技巧的经典实例：我们必须为运行时间写出一个递归关系。对于 N 个数归并排序的用时等于完成两个大小为 N/2 的递归排序所用的时间再加上合并的时间，即：T (N) = 2 * T(N/2) + N (其中，T(1) = 1)。计算可得时间复杂度为 O(N log N)。

虽然归并排序的运行时间是 O(N log N) ，但是它有一个明显的问题，即合并两个已排序的表用到线性附加内存。在整个算法中还要花费将数据拷贝到临时数组再拷贝回来这样一个附加的工作，它明显减慢了排序的速度。这种拷贝可以通过在递归的那些交替层次上审慎地交换 a 和 tmpArray 的角色得以避免。归并排序的一种变形也可以非递归地实现，

与其他的 O(N log N) 排序算法比较，归并排序的运行时间严重依赖于比较元素和在数组 (以及临时数组) 中移动元素的相对开销。

## 7.6 快速排序