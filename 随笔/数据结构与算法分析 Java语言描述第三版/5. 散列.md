# 5 散列
## 5.1 散列的基本思想
理想的散列表数据结构是一个包含一些项的具有固定大小的数组。项可以由一个串 (可以作为关键字) 和其他一些数据域组成。我们把表的大小记作 TableSize ，并将其作为散列的一部分。

散列中，每个关键字被映射到从 0 到 TableSize - 1 这个范围中的某个数，并且被放到适当的单元中，这个映射就叫做散列函数 (hash function) ，理想情况下它的计算很简单，并且应该保证任何两个不同的关键字映射到不同的单元。但这是不可能的，因为单元的数目是有限的，而关键字是用不完的。

我们需要寻找一个散列函数，该函数要在单元之间均匀地分配关键字，还要处理当两个关键字散列到同一值 (即冲突) 时应该如何处理以及如何确定散列表的大小。

## 5.2 散列函数
如果关键字是整数，则一般合理的方法就是直接返回 ``Key mod TableSize`` 。这种情况下，散列函数需要仔细考虑，例如：若 TableSize = 10 而关键字都以 0 为个位时，上述标准的散列函数计算结果无法实现均匀分配。为了避免这样的情况，TableSize 通常为素数。

如果关键字是字符串，有几种散列函数可供选择：
1. 把字符串中字符的 ASCII 码 (或 Unicode 码) 值相加

   ```java
   public static int hash(String key, int tableSize) {
       int hashVal = 0;
   
       for (int i = 0; i < key.length(); i++) {
           hashVal += key.charAt(i);
       }
   
       return hashVal % tableSize;
   }
   ```
   
   上述散列函数实现简单而且能很快计算出答案。但是当表很大时，该函数就无法很好地尽可能均匀分配。假设 TableSize = 10007 ，且所有关键字至多 8 个字符长。由于 ASCII 码的值最多是 127 ，因此散列函数只能假设值在 0 ~ 1016 之间。这显然不是一种均匀的分配。
2. 假设 Key 至少有 3 个字符，值 27 代表英文字母外加一个空格的个数。

   ```java
   public static int hash(String key, int tableSize) {
       return (key.charAt(0) + 27 * key.charAt(1) + 27 * 27 * key.charAt(2)) % tableSize;
   }
   ```
   
   假如前三个字符是随机的，表大小 10007 ，那么得到的分布是较合理的。但是三个字符虽然有 26<sup>3</sup> 种可能组合，但是实际合法的不同的组合数只有 2851 。即使这些组合没有冲突，也只有表的 28% 被真正散列到。
3. 涉及到关键字中的所有字符，根据 Horner 法则计算一个多项式函数，并将结果限制在适当的范围内。

   ```java
   public static int hash(String key, int tableSize) {
       int hashVal = 0;
   
       for (int i = 0; i < key.length(); i++) {
           hashVal = 37 * hashVal + key.charAt(i);
       }
   
       hashVal %= tableSize;
   
       return hashVal < 0 ? hashVal + tableSize : hashVal;
   }
   ```
   
   这个散列函数利用到事实：允许溢出。这可能会引进负数，因此在末尾有附加测试。
   该散列函数就表的分布而言未必是最好的，但极其简单且速度很快。如果关键字特别长，可以挑选其中一部分或只挑选某些位置的字符进行计算，用计算散列函数节省下来的时间来补偿由此产生的对均匀分布的函数的轻微干扰。

## 5.3 分离链接法
**分离链接法 (separate chaining)** 的做法是将散列到同一个值的所有元素保留在一个链表中。如果执行查找，我们需要先通过散列函数确定要遍历哪个链表，在在被确定的链表中进行查找；如果执行插入，我们需要检查相应的链表并将它插在链表头部。

```java
// 分离链接散列表
public class SeparateChainingHashTable<E> {
    public SeparateChainingHashTable() {
        this(DEFAULT_TABLE_SIZE);
    }

    public SeparateChainingHashTable(int size) {
        // 表的大小取素数
        theLists = new LinkedList[nextPrime(size)];
        for (int i = 0; i < theLists.length; i++) {
            theLists[i] = new LinkedList<>();
        }
    }

    public void insert(E x) {
        List<E> whichList = theLists[myhash(x)];
        if (!whichList.contains(x)) {
            // 如果被插入的项已经存在就不执行操作
            whichList.add(x);
            
            if (++currentSize > theLists.length)
                rehash();
        }
    }

    public void remove(E x) {
        List<E> whichList = theLists[myhash(x)];
        if (whichList.contains(x)) {
            whichList.remove(x);
            currentSize--;
        }
    }

    public boolean contains(E x) {
        List<E> whichList = theLists[myhash(x)];
        return whichList.contains(x);
    }

    public void makeEmpty() {
        for (int i = 0; i < theLists.length; i++) {
            theLists[i].clear();
        }
        currentSize = 0;
    }

    private static final int DEFAULT_TABLE_SIZE = 101;

    private List<E>[] theLists;
    private int currentSize;

    private void rehash() {
    }

    private int myhash(E x) {
        int hashVal = x.hashCode();

        hashVal %= theLists.length;
        return hashVal < 0 ? hashVal + theLists.length : hashVal;
    }

    private static int nextPrime(int n) {
        if (n < 2)
            return 2;
        while (!isPrime(++n)) {
        }
        return n;
    }

    private static boolean isPrime(int n) {
        if (n < 2)
            return false;
        else if (n > 2) {
            long len = (long) Math.sqrt(n);
            for (long i = 2; i <= len; i++) {
                if (n % i == 0)
                    return false;
            }
        }
        return true;
    }
}
```

我们定义散列表的 **装填因子 (load factor) λ** 为散列表汇总元素个数和表大小之比。上述例子中，λ = 1.0 。链表的平均长度为 λ 。执行一次查找所需要的工作是计算散列函数值所需要的常数时间加上遍历链表所用的时间。在一次不成功的查找中，要考察的节点数平均为 λ ；一次成功的查找需要遍历大约 1 + (λ/2)<sup>1/2</sup > 个链。可以看出散列表的大小其实并不重要，更重要的是装填因子。分离链接散列法的一般法则是使得表的大小与预料的元素个数大致相等 (λ ≈ 1) 。当装填因子超过 1 时，我们需要通过 rehash 函数扩大散列表的大小，后续会展开说明。

## 5.4 不用链表的散列表
分离链接散列算法的缺点是使用链表时，由于给新单元分配地址需要时间，导致算法的速度有些缓慢。另一种不用链表解决冲突的方法是尝试另外一些单元，直到找出空的单元为止。更常见的是，单元 h<sub>0</sub>(x) ,h<sub>1</sub>(x) ,h<sub>2</sub>(x) ... 相继被试选，其中 h<sub>i</sub>(x) = (hash(x) + f(i)) mod TableSize ,且 f(0) = 0 。函数 f 是冲突解决方法。因为所有的数据都要置入表内，所以这种解决方案所需要的表要比分离链接散列的表大。一般来说，对于不使用分离链接的散列表来说，其装填因子应该低于 λ = 0.5 。我们把这样的表叫做 **探测散列表 (probing hash table)** 。

### 5.4.1 线性探测法
在线性探测法中，函数 f 是 i 的线性函数，典型情形是 f(i) = i 。这相当于相继探测逐个单元 (必要时可以回绕) 以查找出一个空单元。只要表足够大，总能够找到一个自由单元，但是如此花费的时间相当多。更糟的是即使表相对较空，这样占据的单元也会开始形成一些区块，其结果称为 **一次聚集 (primary clustering)** ，就是说，散列到区块中的任何关键字都需要多次试选单元才能够解决冲突，然后该关键字被添加到相应的区块中。

可以证明使用线性探测的预期预测次数对于插入和不成功的查找来说大约为 1/2 (1 + 1 / (1 - λ)<sup>2</sup>) ，而对于成功的查找来说则是 1/2 (1 + 1 / (1 - λ)) 。

一次成功查找的探测次数等于该特定元素插入时所需要的探测次数。当一个元素被插入时，可以看成进行一次不成功查找的结果。因此，我们可以使用一次不成功查找的开销来计算一次成功查找的平均开销。

需要指出的是，λ 从 0 到当前值之间变化，因此早期的插入操作开销较少，从而将平均开销拉低。我们可以通过使用积分计算插入时间平均值的方法来估计平均值，如此得到：

![](插图/5_线性探测法时间平均值公式.png)

如果 λ = 0.75 ，上面的公式指出在线性探测中一次插入预计 8.5 次探测。如果 λ = 0.9 ，则预计为 50 次探测。假如聚集不是问题，那么这可与相应的装填因子的 4 次和 10 次探测相比。从这些公式看到，如果表可以有多于一半被填满的话，那么线性探测就不是个好办法。然而如果 λ = 0.5 ，那么插入操作平均只需要 2.5 次探测，并且对于成功的查找平均只需要 1.5 次探测。

### 5.4.2 平方探测法